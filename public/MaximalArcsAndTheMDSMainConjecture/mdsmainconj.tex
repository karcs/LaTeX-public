\section{The MDS main conjecture}%
\makeatletter%
\def\@currentlabel{Section \thesection}%
\makeatother% TODO better section command
\label{sec-mds-connections}

In this section we come to a very interesting open problem which is formulated in coding theory, finite projective geometry, the theory of hyperplane arrangements and matroid theory.

\subsection{Projective arcs}

We now introduce another concept which coincides with the one of a $(k,m)$-arc (see \autoref{kmarc-def}) in dimension two for $m=2$.

\begin{definition}[projective arc]
    A set $\cA\setleq \P K^n$ is called a \keyword{projective arc} if no $n$ points of $\cA$ lie in a common hyperplane (if we aim to emphasize the number of points in $\cA$ we call it a $k$-arc when $\card\cA=k$).
    A set $\cA'\setleq K^n$ such that $\cA\defeq\set{\gen a}[a\in\cA']$ is a projective arc and $\gen a\neq\gen b$ for $a,b\in\cA'$ is called a \keyword{representation} of the arc $\cA$.
\end{definition}

\begin{remark}
    As we consider only Desarguian spaces, the above definition is not given for non-Desarguian planes.
\end{remark}

For the classification of projective arcs it makes sense to consider them under some natural equivalence relations, such as the ones induced by $\PGL$ or $\PGammaL$. We call two arcs \keyword{$\PGL$-equivalent} or \keyword{$\PGammaL$-equivalent} if there are elements of the corresponding groups mapping one to the other (as a set). 

Apart from the `duality principle' for maximal $(k,m)$-arcs there is another duality principle for projective arcs.

\begin{definition}[dual projective arc]\label{def-dual-arc}
    Let $\cA\setleq K^n$ a representation of a projective arc in $\P K^n$ and $n+1\leq \card\cA$. Consider the canonical map
    $$\pi:\dirsum_{a\in\cA}{Ka}\to K^n$$
    given by
    $$\dirsum_{a\in\cA}{\lambda_a a}\mapsto \sum_{a\in\cA}{\lambda_a a}$$
    and define
    $$\pi_a:\dirsum_{a'\in \cA}{Ka'}\to K$$
    as the projection to the summand $a$.
    Choose a basis $\cB$ of $\ker \pi$. Then
    $$
    \cA'\defeq\set{\sum_{b\in\cB}{(\pi_a b)b}}[a\in\cA]
    $$
    is a representation of a projective arc in $\ker \pi \iso K^{\card\cA -n}$.
    This is called the \keyword{dual arc} of the one represented by $\cA$.
\end{definition}
\begin{remark}
Of course this definition depends on the choice of the basis $\cB$, but it defines the dual arc up to $\PGL$-equivalence.
\end{remark}

We are left to prove that $\cA'$ is indeed a representation of projective arc in $\ker\pi\iso K^{\card\cA-n}$.

\begin{proof}    
Consider a non-trivial linear combination of elements of $\cA'$ which evaluates to zero.
$$
\sum_{a\in\cA}{\lambda_a\sum_{b\in\cB}{(\pi_a b)b}}=\sum_{b\in\cB}{\left(\sum_{a\in\cA}{\lambda_a(\pi_a b)}\right)b}=0.
$$
As $\cB$ is linearly independent, we have
$$
\left(\sum_{a\in\cA}{\lambda_a\pi_a}\right)b=0
$$
for all $b\in\cB$ --- that is $\ker\pi\setleq \ker{\sum_{a\in\cA}{\lambda_a\pi_a}}$. But any element of $c\in\ker \pi$ must either be zero or at least $n+1$ summands $\pi_a c$ of it do not vanish ($a\in \cA$). As $\card\cA>n$ we have $\ker\pi\neq 0$ and it follows that $\lambda_a\neq 0$ for at least $\card\cA-n+1$ elements $a\in\cA$. Assume the contrary, that $\lambda_a\neq 0$ for $a\in A\setleq \cA$ with $\card A\leq \card\cA-n$. Then choose an $(n+1)$-subset $B$ of $\cA$ such that $B\setmeet A=\set{c}$ and a non-trivial linear combination $\sum_{b\in B}{\mu_b b}=0$ with $\mu_c\neq 0$.
This implies that $\dirsum_{b\in B}{\mu_b b}\in\ker \pi$ and
$$
\left(\sum_{a\in A}{\lambda_a\pi_a}\right)\left(\dirsum_{b\in B}{\mu_b b}\right)=\lambda_c\mu_c\neq 0, 
$$
a contradiction showing that any $\card\cA-n$ elements of $\cA'$ are linearly independent.
\end{proof}

The duality principle for projective arcs is completely analogous to the duality principle for MDS codes (see \autoref{lincode-dual}).
When $\cA$ is an arc we write $\dual\cA$ for its dual arc.

A simple fact which is implied by the above is the following
%
\begin{corollary}\label{mds-ngeqq}
    Let $\cA$ be a projective arc in $\P \field{q}^n$ where $q\leq n$. Then $\card\cA\leq n+1$ and all maximal examples with respect to cardinality are $\PGL$-equivalent to $\set{\gen{e_0},\ldots,\gen{e_{n-1}},\gen{e_0+\cdots+e_{n-1}}}$. Moreover, $\cA$ is extends to such an arc.
\end{corollary}

\begin{proof}
    Assume that $\cA$ is a projective arc in $\P \field{q}^n$ of cardinality $n+2$. Then $\dual\cA$ has the same cardinality in is a projective arc in $\P \field{q}^2$ --- thus $\card{\dual\cA}\leq q+1$ (as there are only $q+1$ one-dimensional linear subspaces of $\field{q}^2$). This implies $\card\cA=n+2\leq q+1$ so $n<q$.
    The second claim follows from the fact that $\PGL(n,K)$ acts sharply transitive on the $(n+1)$-tuples in general linear position.
    We briefly demonstrate this. Let $\seq{a_i}_{i=0}^n$ and $\seq{b_i}_{i=0}^n$ be in general linear position. We may assume then that $a_0=\sum_{i=1}^n{\lambda_i a_i}$ and $b_0=\sum_{i=1}^n{\mu_i b_i}$ ($\lambda_i,\nu_i\in \units K$, $i=1,\ldots,n$).
    A preimage $A\in\GL(n,K)$ of an element $B\in\PGL(n,K)$ which sends $\gen{a_i}$ to $\gen{b_i}$ must map $a_i$ to $\nu_i b_i$ ($\nu_i\in \units K$, $i=\range 0 n$). By linearity of $A$ it follows from
    $$
    Aa_0=A\left(\sum_{i=1}^n{\lambda_i a_i}\right)=\nu_0 b_0=\nu_0\left(\sum_{i=1}^n{\mu_i b_i}\right)=\sum_{i=1}^n{\lambda_i\nu_i b_i}
    $$
    that $\nu_i=\nu_0\frac{\mu_i}{\lambda_i}$ for $i=1,\ldots,n$. Thus $A$ is defined up to scalar factor $\nu_0\in \units K$ so $B$ exists uniquely.
    The third claim is obvious.
\end{proof}
%%
\subsection{Generic hyperplane arrangements}

We start by introducing a new concept.

\begin{definition}[generic and central generic hyperplane arrangement]
    An arrangement $\cA$ of (affine) hyperplanes in $V=K^n$ is called \keyword[generic arrangement of hyperplanes]{generic} if for any set of hyperplanes $\cH\setleq\cA$ it holds that $\codim_{\Aff}{\Setmeet\cH}=\card\cH$ if $\card{\cH}\leq n$ and $\Setmeet\cH=\emptyset$ otherwise.
    Similarly, $\cA$ is called a \keyword[central generic arrangement of hyperplanes]{central generic arrangement} if for any set of hyperplanes $\cH\setleq\cA$ we have $\codim{\Setmeet\cH}=\min\set{n,\card{\cH}}$.
\end{definition}

\begin{remark}
    It is then clear that the concept of a central generic arrangement is the same as the concept of an arc in $\P \dual V$ via the map associating a linear form with its kernel.
\end{remark}

We will get back to this interpretation a little later in \autoref{sec-gen-hyperplane-arr} and in the formulation of the MDS main conjecture.

\subsection{Linear codes and the \person{Singleton} bound}

Recall the following definitions

\begin{definition}[$(n,k)$-linear code]
    A linear code of length $n$ and rank $k$ (also denoted as $(n,k)$-linear code) over a field $K$ is a $k$-dimensional subspace of $K^n$.  
\end{definition}

\begin{definition}
    Let $\cC\leq K^n$ be linear code. A \keyword{generator matrix} $G$ of $\cC$ is a matrix having as its rows the coordinate vectors of a basis of $\cC$ (with respect to the canonical basis of $K^n$). A \keyword{check matrix} $H$ of $\cC$ is a fully ranked matrix having as its kernel the coordinate vectors of $\cC$.
\end{definition}

As for projective arcs it is meaningful to introduce equivalence relations for linear codes, too.
\begin{definition}
    Let $\cC,\cC'$ be a $(n,k)$-linear codes over $K^n$. Then we say $\cC$ and $\cC'$ are $\units K\wr S_n$-equivalent or $(\units K\rtimes\Aut K)\wr S_n$-equivalent if there are elements of the corresponding groups acting by multiplication, application of a field automorphism and permutation on the coordinates mapping $\cC$ to $\cC'$.
\end{definition}


\begin{definition}[minimum weight and \person{Hamming} distance]
    The \keyword{\person{Hamming} distance} $d_H$ is a metric on $K^n$ given by
    $$
    d_H(a,b)\defeq\card{\set{i\in n}[a_i\neq b_i]}
    $$
    for $a,b\in K^n$ where the $a_i$ and $b_i$ denote the coordinates of $a$ and $b$ in the canonical basis.
    Similarly, we define
    $$
    w_H(a)\defeq d_H(a,0)
    $$
    as the \person{Hamming} distance to zero and call it the \keyword[weight of a vector]{weight} of $a$.
    Moreover, the \keyword{\person{Hamming} weight} or \keyword{minimum weight} $d(\cC)$ of an $(n,k)$-linear code is the minimum \person{Hamming} distance between two of its points.
    This is
    $$
    d(\cC)\defeq \min\set{w_H(c)}[c\in\cC\setminus\set{0}],
    $$
    since $d_H$ is obviously additively invariant.
    An $(n,k)$-linear code with \person{Hamming} weight $d$ is also denoted as an $(n,k,d)$-linear code.
\end{definition}

We are interested in special linear codes called MDS codes. To see from where they arise, consider the following lemma.

\begin{lemma}[\person{Singleton} bound]
    Let $\cS\setleq \field{q}^n$ be a set such that any two distinct points of $\cS$ have at least \person{Hamming} distance $d$. Then
    $$
    \card{\cS}\leq q^{n-d+1}.
    $$
    Similarly, an $(n,k)$-linear code $\cC$ over an arbitrary field $K$ with $d(\cC)\geq d$ has dimension $k\leq n-d+1$.
\end{lemma}

\begin{proof}
    Consider the projection map $\pi:\field{q}^n\to\field{q}^{n-d+1}$ which forgets $d-1$ coordinates.
    Then $\pi$ is injective on $\cS$ since otherwise $\cS$ would have two distinct points differing in less than $d$ coordinates contradicting the assumptions, proving the first claim.
    The second claim follows analogously from the fact that $\pi:K^n\to K^{n-d+1}$ maps $\cC$ injectively into a $(n-d+1)$-dimensional space showing that $\dim{\cC}\leq n-d+1$.
    This finishes the proof.
\end{proof}

This motivates the definition of MDS codes.

\begin{definition}[linear MDS code]
    An $(n,k,d)$-linear code $\cC$ is called \keyword[maximum distance separable code]{maximum distance separable} or $(n,k)$-\keyword{MDS code} if the singleton bound is fulfilled with equality, i.e. $k=n-d+1$. 
\end{definition}

A very important concept for linear codes and especially for MDS codes is \keyword{duality}.

\begin{definition}[dual code]\label{lincode-dual}
    Let $\cC\leq K^n$ be a linear code of dimension $k$. The \keyword{dual code} $\dual\cC$ of $\cC$ is defined as $\dual\cC\defeq\set{\dual c\in \dual{K^n}}[\cC\leq \ker \dual c]$. The dual code is thus of codimension $k$.
\end{definition}

\begin{remark}
    It is thus clear that a generator matrix $G$ of $\cC$ is a check matrix of $\dual\cC$ and vice versa.
\end{remark}

We can characterize the minimum weight of a code via its check and generator matrices.

\begin{lemma}[Characterization of the minimum weight via associated matrices]\label{char-min-weight-matrices}
    Let $\cC\leq K^n$ be a linear code of dimension $k$. Then $\cC$ has minimum weight $d$ if and only if one of the following conditions holds true.
    \begin{statements}
            \item\label{char-min-weight-check-matrix} For any check matrix $H\in K^{(n-k)\setprod n}$ of $\cC$ the number $d$ is the minimal number of linear dependent columns of $H$. Or alternatively, $d-1$ is the maximum of the numbers $e\in\nats$ such that any $e$ columns of $H$ are linearly independent.
            \item\label{char-min-weight-gen-matrix} For any generator matrix $G\in K^{k\setprod n}$ of $\cC$ the number $n-d$ is the maximal number of columns of $G$ such that the rows of the submatrix corresponding to these columns are linearly dependent. Or alternatively, $n-d+1$ is the minimum of the numbers $f\in\nats$ such that any submatrix of $G$ consisting of $f$ columns has linearly independent rows.
    \end{statements}
\end{lemma}

\begin{proof}
    \begin{implications}
            \item[$\autoref{char-min-weight-check-matrix}$:] Each vector $\seq{\range{c_0}{c_{n-1}}}$ corresponds to a linear combination $\sum_{i=0}^{n-1}{c_i h_i}$ where $h_i$ are the columns of $H$. Thus each non-zero vector $c\in\cC$ corresponds to a non-trivial linear combination of columns of $H$.

            \item[$\autoref{char-min-weight-gen-matrix}$:] Similarly, if $G$ is a generator matrix then any non-zero vector $c\in\cC$ can be uniquely written as $c=G^{\top} x$ for $x\in K^k$. Thus any vector $c\in\cC\setminus\set 0$ having weight $w$ corresponds to a $k\setprod (n-w)$-submatrix of $G$ having linearly dependent rows.
    \end{implications}
    Hence, we are done with the proof.
\end{proof}
%% END new

It is now easy to characterize linear MDS codes via their associated matrices.

\begin{lemma}[characterization of MDS codes]\label{mdschar}
    Let $\cC$ be an $(n,k,d)$-linear code. Then the following are equivalent
    \begin{statements}
            \item\label{mds} $\cC$ is MDS.
            \item\label{mds-chkmtrx} A check matrix $H \in K^{(n-k)\setprod n}$ has the property that any maximal square submatrix of it is regular.
            \item\label{mds-gmtrx} A generator matrix $G \in K^{k\setprod n}$ has the property that any maximal square submatrix is regular.
            \item\label{mds-dual} The dual code $\dual \cC$ is MDS.
    \end{statements}
\end{lemma}

\begin{proof}
    \begin{implications}
            \item[$\autoref{mds}\equival\autoref{mds-chkmtrx}$:]
        The property of $\cC$ that $d(\cC)=d=n-k+1$ implies the property of a check matrix $H$ of $\cC$ that any $(n-k)\setprod (n-k)$-submatrix of $H$ has independent rows and is thus regular by the previous lemma. On the other hand, if every such matrix is regular then its rows are linearly independent and so $d-1\geq n-k$ again by \autoref{char-min-weight-matrices}. But $d-1\leq n-k$ holds as well by the \person{Singleton} bound.
            \item[$\autoref{mds}\equival\autoref{mds-gmtrx}$:]
        The property of $\cC$ that $d(\cC)=n-k+1$ implies the property of a generator matrix $G$ of $\cC$ that any $k\setprod k$-submatrix of $G$ has linearly independent rows and is thus regular. Conversely, if any $k\setprod k$-submatrix is regular then its rows are linearly independent and thus by \autoref{char-min-weight-matrices} $n-d+1\leq k$. The reverse inequality again holds by the \person{Singleton} bound. 
            \item[$\autoref{mds}\equival\autoref{mds-dual}$:]
        A generator matrix of $\cC$ is a check matrix of $\dual\cC$ and vice versa. By the last two equivalences $\cC$ and $\dual\cC$ can only be MDS codes at the same time. 
    \end{implications}%
This completes the proof.
\end{proof}

To fix this interesting type of matrices which are a check (or generator) matrix of an MDS code we make the following

\begin{definition}[principally regular matrix]
    A matrix $A$ over some ring $R$ such that any maximal square submatrix of $A$ is regular is called \keyword{principally regular matrix}.
\end{definition}

There is a very simple connection between this type of matrix and another type of matrix.

\begin{definition}[totally regular matrix]
    Let $B$ be a matrix such that any square submatrix of $B$ is regular. Then $B$ is called \keyword[totally regular matrix]{totally regular}\footnote{Regrettably, the denotation of these matrices in the literature and different papers is not very consistent}. 
\end{definition}

We briefly demonstrate the connection between these two types of matrices.

\begin{lemma}[connection between principally and totally regular matrices]
    Let $C\defeq(A|B)\in R^{m\setprod n}$ be some matrix over a ring $R$ and $m\leq n$ where $A\in R^{m\setprod m}$.
    Then the following two are equivalent.
    \begin{statements}
            \item\label{prin-reg} $C$ is principally regular.
            \item\label{invert-tot-reg} $A$ is invertible and $A^{-1}B$ is totally regular.
    \end{statements}
\end{lemma}

\begin{proof}
    We only proof the direction $\autoref{prin-reg}\implies\autoref{invert-tot-reg}$ since the other is obvious.
    When $C$ is principally regular then $A$ is invertible so that $A^{-1}C$ is also principally regular. Now let $k\leq \min\set{m,n-m}$. Choosing $k$-sets $I\setleq\set{\range 0 {m-1}}=m$ and $J\setleq \set{\range m {n-m-1}}=n\setminus m$ we can check the matrix $\rest{A^{-1}C}_{m\setprod (m\setminus I\setjoin J)}$ for regularity which is easily seen to be equivalent to the fact that $\rest{A^{-1}B}_{I\setprod J}$ is regular.

    This is mainly based on the fact that the matrix
    $$
    \begin{pmatrix}
        1 & X \\
        0 & Y
    \end{pmatrix}
    $$
    over a ring $R$ is regular if and only if $Y$ is regular and admits the inverse
    $$
    \begin{pmatrix}
        1 & -XY^{-1}\\
        0 & Y^{-1}
    \end{pmatrix}
    $$
    and using an appropriate permutation we can achieve that $\rest{A^{-1}C}_{m\setprod (m\setminus I\setjoin J)}$ is of the upper form and $\rest{A^{-1}B}_{I\setprod J}$ corresponds to $Y$.
\end{proof}

\subsection{Connections}

Having introduced several probably new concepts and ideas, we now start by drawing some connections between these.

We already saw how MDS codes and principally or totally regular matrices are related.
To draw the connection to projective arcs we interpret the one-dimensional subspaces of the columns of a check matrix $H$ of an $(n,k)$-MDS code over $K$ as elements of the projective space $\P \col H\iso \P K^{d-1}$ (as $d=n-k+1$). This gives us a projective arc of size $n$ which is uniquely determined by the code up to $\PGL$-equivalence (by the choice of the check matrix and by forgetting scalar factors).

Conversely, starting from a projective arc $\cA$ in $\P K^{d-1}$ we can reconstruct the original MDS code only up to $\units K\wr S_n$-equivalence, since the elements of $\cA$ are not ordered and a representative of a one-dimensional subspace is only defined up to scalar factor. This shows that $\units K\wr S_n$-orbits of MDS codes are in a one-to-one relation with $\PGL$-orbits if projective arcs (the same holds for $(\units K\rtimes \Aut K)\wr S_n$-orbits of MDS codes and $\PGammaL$-orbits of projective arcs).

On the other hand, given an arc $\cA$ in $\P K^n$ we can get a central generic arrangement $\cB$ of hyperplanes by interpreting the elements of $\cA$ as (non-zero) linear forms $\cF$ in $\dual{K^n}$ (which can be chosen up to scalar factor). Then $\cB\defeq\set{\ker f}[f\in \cF]$ is the associated central generic arrangement.
Finally, we can get an (affine) generic arrangement from a non-empty
central generic one by a deconing construction. If
$P_{\cA}(\range{X_0}{X_{n-1}})=\prod{\cF}\in\field{q}[X_0,\ldots,X_{n-1}]$
is the defining polynomial of $\cA$ with respect to the basis
$\range{x_0}{x_{n-1}}$ (i.e. $P_\cA(\range{\dual x_0}{\dual
    x_{n-1}})=\prod_{H\in\cA}{l_H}$ where $\ker l_H =H$) 
and $\ker\dual x_0\in\cA$ then the affine
generic arrangement $\cA^{\aff}$
arising  from that by deconing $\mathcal{A}$ has defining polynomial $P_{\cA^{\aff}}(X_1,\ldots,X_{n-1})=P_{\cA}(1,X_1,\ldots,X_{n-1})$ with respect to the basis $x_1,\ldots,x_{n-1}$ of $\pi_{(1,\ldots,n-1)}\field{q}^n$ (that is the intersection of the hyperplanes in $\mathcal{A}$ with the one given by $x_0=1$).

\begin{conjecture}[main conjecture on MDS codes, projective arcs, generic arrangements in $\field{q}^n$]
  Let $m(n,q)$ be the minimum of all integers $m$ such that $\card\cA\leq m$ for any arc $\cA$ in a projective space of dimension $n$ and order $q$ then
  $$
    m(n,q)=\begin{cases}
      n+2 :& n \geq q\\
      q+2 :& n\in\{2,q-1\} \lgand 4\divides q\\
      q+1 :& \otherwise
    \end{cases}.
    $$
\end{conjecture}

\begin{remark}%%%
    We fully proved the conjecture for $n\geq q$ (see \autoref{mds-ngeqq}) characterizing the sets $\cA$ of maximal cardinality. For $n=2$ it is (as we have shown) a consequence of \autoref{kmarc-size} and \autoref{kmarc-dual} and the classification of sets $\cA$ of maximal cardinality in the case of even $q$ or non-Desarguian planes seems to be very difficult. In the case where $q$ is odd and the plane is Desarguian, we will see that these sets $\cA$ are precisely non-singular conics (this will be a consequence of \autoref{mds-class-n-leq-p}). 
\end{remark}

\begin{remark}\label{mds-mainconjotherobj}
    Equivalently, $m(n,q)-1$ is the minimum of integers $m'$ such that for all generic hyperplane arrangements $\cB$ in $\field{q}^n$ it holds that $\card{\cB}\leq m'$ or $m(k-1,q)$ is minimal among all $m''$ such that all $(n,k)$-MDS codes $\cC$ over $\field{q}$ satisfy $n\leq m''$. This can easily be seen from the connections we have drawn.
\end{remark}

%\begin{proof}[\autoref{mds-mainconjotherobj}]% BUG
    %% %todo
%\end{proof}




