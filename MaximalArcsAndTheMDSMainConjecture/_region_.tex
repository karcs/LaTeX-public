\message{ !name(OnTheRAIDProblem.tex)}\documentclass[8pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\input{../MathFiles/math.tex}
\begin{document}

\message{ !name(OnTheRAIDProblem.tex) !offset(-3) }

\title{On the existence of certain generic and weakly generic arrangements in $\field_q^d$}
\author{Jakob Schneider}
\date{\today}
\maketitle
\begin{abstract}
We discuss the question if a weakly generic arrangement with given \textsc{Poincaré}-polynomial can exist in $\field_q^d$ and generalise some results by \textsc{Zaslavsky} about the number of components of real arrangement and its discrete analogue for that type of arrangemnts.
Secondly, we treat this question for generic arrangements and show that it is equivalent to an open problem about linear MDS codes or maximal arcs in finite projective spaces.
Using a graph theoretical approach, we draw some connections between this problem and the graphs $KG(2d-3,d-2)$ simplifying some proofs of the papers of Simeon Ball and Jan De Beule.
\end{abstract}

\section{Existence of weakly generic arrangements in $\field_q^d$ with given Poincaré polynomial}

Let $\mathcal{A}$ be an arrangement of hyperplanes in $\field_q^d$ and $\mathcal{L}(\mathcal{A}):=\{\intersection \mathcal{H} : \mathcal{H}\subset \mathcal{A} \lgand \intersection{\mathcal{H}}\neq \emptyset\}$ the associated $\meet$-lattice, where for $X,Y\in\mathcal{L}(\mathcal{A})$ we define $X\meet Y:=\intersection\{Z\in\mathcal{L}(\mathcal{A}):Z\supset X,Y\}$ and $X\join Y:= X\setmeet Y$.
Moreover, we assign to $\mathcal{L}(\mathcal{A})$ the rank function $r:\mathcal{L(\mathcal{A})}\to \nats$ where $X\mapsto \codim_{\aff}(X)$.
It is then an interesting question, which restrictions on the geometric $\meet$-lattice $\mathcal{L}(\mathcal{A})$ arise from the structure of the space $\field_q^d$. We want to discuss this question for a special type of arrangements.

We need the following definitions.

\begin{definition}[unique representation of lattice elements] Let $\mathcal{A}$ be an arrangement of hyperplanes in $V$ and $L(\mathcal{A})$ the corresponding poset. Then we call $X\in L(\mathcal{A})$ a \emph{uniquely representable} element if there is a unique set of atoms (hyperplanes) $S\subset\mathcal{L}(\mathcal{A})$ such that $X=\bigjoin {S}$ (clearly, $\abs{S}=r(X)$).
\end{definition}

\begin{remark}
If $X\in\mathcal{L}(\mathcal{A})$ is uniquely representable and $Y\leq X$ then is also uniquely representable. 
\end{remark}

\begin{definition}[weakly generic arrangement]
Let $\mathcal{A}$ be an arrangement such that any element $X\in\mathcal{L}(\mathcal{A})$ is uniquely representable. Then $\mathcal{A}$ is called \emph{weakly generic}.
\end{definition}

A fact, which is also obvious is that a geometric $\meet$-lattice $\mathcal{L}$ is the lattice $\mathcal{L}(\mathcal{A})$ for an arrangement $\mathcal{A}$ in $\field_q^d$ if and only it is embedded in $\mathcal{L}(\mathcal{\bar{A}})$ (by a rank preserving map) where $\bar{\mathcal{A}}$ is the arrangement consisting of all affine subspaces of $\field_q^d$. However, it turns out to be very difficult to decide this for a given lattice.
But at first to discuss this question with even less information, namely the question if there is a weakly generic arrangement $\mathcal{A}$ in $\field_q^d$ with given \textsc{Poincaré}-polynomial.

\subsection{Some combinatorial facts about weakly generic arrangements}

In this section we generalize some combinatorial results by \textsc{Zaslavsky} about the number of components of the complement $\mathcal{M}(\mathcal{A})=:\mathcal{M}_0(\mathcal{A})$ and its analogue in the discrete case.

\begin{lemma}[point numbers of the strata $\mathcal{M}_m$ of arrangements in finite vector spaces]
Let $\mathcal{A}$ be a weakly generic arrangement in $\field_q^d$. Then one has
\begin{equation}
\abs{\mathcal{M}_m(\mathcal{A})}= q^{d-m}\frac{\pi^{(m)}(\mathcal{A},-q^{-1})}{m!}
\end{equation}
where $\mathcal{M}(\mathcal{A})$ denotes the $m$-th stratum ($m\geq 0$)
\begin{equation}
\mathcal{M}(\mathcal{A}):=\union\{X\in\mathcal{L}(\mathcal{A})\lgand r(X)=m\}\setminus\union\{X\in\mathcal{L}(\mathcal{A}):r(X)=m+1\}\text{.}
\end{equation}
For $m=0$ the arrangement does not have to be weakly generic (\textsc{Zaslavsky}'s result ...).
\end{lemma}

The proof of this fact is just based on Möbius inversion

\begin{proof}
We start with $m=0$.
As $\distunion_{X\in\mathcal{L}(\mathcal{A})}{\mathcal{M}_0(\mathcal{A}^X)}=\field_q^d$ (where $\mathcal{A}^X$ denotes the restriction of $\mathcal{A}$ on $X$) we have that (for $Y\in\mathcal{L}(\mathcal{A})$)
\begin{equation}
\sum_{\substack{X\in\mathcal{L}(\mathcal{A})\\ X\geq Y}}{\abs{\mathcal{M}_0(\mathcal{A}^X)}}=q^{d-r(Y)}\text{.}
\end{equation}
Möbius inversion transforms this equation to
\begin{equation}
\sum_{X\in\mathcal{L}(\mathcal{A})}{\mu(V,X)q^{d-r(X)}}=q^d\pi(\mathcal{A},-q^{-1})=\abs{\mathcal{M}_0(\mathcal{A})}\text{.}
\end{equation}
This is essentially a result analogue to the lemma proved by \textsc{Zaslavsky} in ... . Note that we did not use that $\mathcal{A}$ is weakly generic.
For the case $m>0$ we obtain
\begin{equation}
\abs{\mathcal{M}_m(\mathcal{A})}=\sum_{\substack{X\in\mathcal{L}(\mathcal{A})\\ r(X)=m}}{\abs{\mathcal{M}_0(\mathcal{A}^X)}}=\sum_{\substack{X\in\mathcal{L}(\mathcal{A})\\ r(X)=m}}{\sum_{Y\in\mathcal{L}(\mathcal{A}^X)}{\mu_{\mathcal{A}^X}(X,Y)q^{d-r(Y)}}}\text{.}
\end{equation}
Now, we use the fact (which can be easily shown by induction) that for a weakly generic arrangement $\mathcal{A}$ we have $\mu(X,Y)=(-1)^{r(X)-r(Y)}$ and as restrictions of weakly generic arrangements are again weakly generic, we obtain from the above
\begin{align}
\abs{\mathcal{M}_m(\mathcal{A})} & =q^d\sum_{Y\in\mathcal{L}(\mathcal{A})}{(-1)^{m-r(Y)}\binom{r(Y)}{m}q^{-r(Y)}}\\
& = q^d\frac{\pi^{(m)}(\mathcal{A},-q^{-1})}{m!}
\end{align}
which finishes the proof.
\end{proof}

For the sake of completeness, we shall give the real analogue of that last fact

\begin{lemma}[number of connected components of the stratum $\mathcal{M}_m(\mathcal{A})$ of an arrangement] Let $\mathcal{A}$ be a weakly generic arrangement in the vector space $V$ over $\reals$. Then it holds that
\begin{equation}
\frac{\pi^{(m)}(\mathcal{A},1)}{m!}=\abs{\comp(\mathcal{\mathcal{M}}_m(\mathcal{A}))}\text{.}
\end{equation}
For $m=0$ the arrangement does not have to be weakly generic (\textsc{Zaslavsky}'s result ...).
\end{lemma}

Here, the proof is analogous.

\begin{proof}
Starting with $m=0$, we can apply \textsc{Euler}'s formula gives (for $Y\in\mathcal{L}(\mathcal{A})$)
\begin{equation}
\sum_{\substack{X\in\mathcal{L}(\mathcal{A})\\ X\geq Y}}{(-1)^{r(Y)-r(X)}\abs{\comp(\mathcal{M}_0(\mathcal{A}^X))}}=1=\chi(\reals^{d-r(Y)})\text{.}
\end{equation}
Möbius inversion delivers
\begin{equation}
\sum_{X\in\mathcal{L}(\mathcal{A})}{\mu(V,X)(-1)^{r(Y)}}=\pi(\mathcal{A},1)=\abs{\comp(\mathcal{M}_0(\mathcal{A}))}\text{.}
\end{equation}
For $m>0$, the proof is identical with the last one
\begin{align}
\abs{\comp(\mathcal{M}_m(\mathcal{A}))} &=\sum_{\substack{X\in\mathcal{L}(\mathcal{A})\\ r(X)=m}}{\abs{\comp(\mathcal{M}_0(\mathcal{A}^X))}}\\
&=\sum_{\substack{X\in\mathcal{L}(\mathcal{A})\\ r(X)=m}}{\sum_{Y\in\mathcal{L}(\mathcal{A}^X)}{\mu_{\mathcal{A}^X}(X,Y)(-1)^{r(X)-r(Y)}}}\text{.}
\end{align}
Now, use that $\mu(X,Y)=(-1)^{r(X)-r(Y)}$ if $\mathcal{A}$ is weakly generic and as restrictions of weakly generic arrangements are again weakly generic, we obtain from the above
\begin{align}
\abs{\comp(\mathcal{M}_m(\mathcal{A}))} & =\sum_{Y\in\mathcal{L}(\mathcal{A})}{\binom{r(Y)}{m}}\\
& = \frac{\pi^{(m)}(\mathcal{A},1)}{m!}
\end{align}
finishing the proof.
\end{proof}

\begin{remark}
An alternative proof of the last two lemmas can be given via deletion restriction theorem and the identity $\pi(\mathcal{A},t)=\pi(\mathcal{A}',t)+t\pi(\mathcal{A}'',t)$. The $m$-th derivative of this last identity behaves analogue to some recurrence relations of the above numbers for $(\mathcal{A},\mathcal{A}',\mathcal{A}'')$ a generic triple of arrangements.
\end{remark}

\begin{corollary}
Let $\mathcal{A}$ be a weakly generic arrangement in $\field_q^d$. Then it holds that $\pi(\mathcal{A},t)=\pi_q(\mathcal{A},t+q^{-1})$ for a polynomial $\pi_q(\mathcal{A},t)$ with positive coefficients.
\end{corollary}

This corollary gives a partial answer to out question, but its statement only uses the lattice structure and is careless about the nature of the sets of that lattice (as linear subspaces). It turns out that this answer is not very sharp in some cases.

\subsection{Translational pertubations of arrangements}

Next, we study what happens if one modifies the hyperplanes $H$ of an arrangement $\mathcal{A}$ by translations $\{\theta_H\}_{H\in\mathcal{A}}$ such that the new arrangement is closer to a weakly generic one.

At first we need some definitions

\begin{definition}[translational pertubation of an arrangement]
Let $\mathcal{A}$ and $\mathcal{B}$ be arrangements. We say that $\mathcal{B}$ is a \emph{translational pertubation} of $\mathcal{A}$ via the family of translations $\{\theta_H\}_{H\in\mathcal{A}}$ if $H^{\phi_H}$ are the (distinct) hyperplanes of $\mathcal{B}$ ($H\in\mathcal{A}$).
\end{definition}

\begin{definition}[pure pertubation]
Let $\mathcal{B}$ be a translational pertubation of the arrangement $\mathcal{A}$ via the tranlations $\{\theta_H\}_{H\in\mathcal{A}}$. We say that $\mathcal{B}$ is a \emph{pure pertubation} of $\mathcal{A}$ via $\{\theta_H\}_{H\in\mathcal{A}}$ if it holds that if 
\begin{equation}
X=\bigjoin\{H_i^{\theta_{H_i}}:i=1,\ldots,l\}=\bigjoin\{J_i^{\theta_{J_i}}:i=1,\ldots,m\}\in\mathcal{L}(\mathcal{B})
\end{equation} has two representations in atoms then 
\begin{equation}
\bigjoin\{H_i:i=1,\ldots,l\}=\bigjoin\{J_i:i=1,\ldots,m\}\in\mathcal{L}(\mathcal{A})\text{.}
\end{equation}
\end{definition}

\begin{remark}
If $\mathcal{B}$ is a pure translational perturbation of $\mathcal{A}$ via $\{\theta_H\}_{H\in\mathcal{A}}$ then there is a unique epimorphism $\phi:\mathcal{L}(\mathcal{B})\to\mathcal{L}(\mathcal{A})$ which satisfies $H^{\theta_H}\mapsto H$. First, note that the uniqueness follows from the fact that $\phi$ is defined on atoms of $\mathcal{B}$. To see that $\phi$ exists,
pick $X\in\mathcal{L}(\mathcal{A})$ such that $X=\bigjoin\{H_i^{\theta_{H_i}}:i=1,\ldots,l\}$. Then it must hold that $\phi(X)=\bigjoin\{H_i:i=1,\ldots,l\}$. The above definition ensures that this last equation is also a definition (this is basically the notion of the homomorphism theorem).
We call $\phi:\mathcal{B}\to\mathcal{A}$ the natural map with respect to the pertubation via $\{\theta_H\}_{H\in\mathcal{A}}$. 
\end{remark}

\begin{definition}[universal translational perturbation]
etc.
\end{definition}

The following lemma shows that the question of the existence of a universal translational pertubation in infinite vector spaces has a simple answer.

\begin{lemma}[existence of universal translational perturbations in infinite vector spaces]
If $\mathcal{A}$ is an arrangement in some $\field$-vector space of infinite dimension or where $\abs{\field}=\infty$ then there exists a universal translational perturbation $\mathcal{A}^{\tpert}$
\end{lemma}

\begin{proof}
... argument ...
\end{proof}

---TO BE CONTINUED


When $\mathcal{A}$ is an arrangement in a finite vector space, it is a very difficult problem to say if $\mathcal{A}^{\tpert}$ exists.

\section{Maximal generic arrangements in $\field_q^d$ and related problems}

We start by drawing some connections between some objects related to this last question.
It turns out, that there is a (up to projective equivalence) 'one-to-one' correspondance between the following concepts.

\begin{definition}[linear MDS code]
A linear $(n,k,d)$-code $\mathcal{C}$ is called \emph{maximum distance separable} or \emph{MDS code} if it satisfies the singleton bound with equality $d=n-k+1$. 
\end{definition}

\begin{definition}[totally regular matrix]
Let $M\in\field_q^{n\times m}$ ($n\leq m$) such that any square submatrix of $M$ is regular. Then $M$ is called totally regular. 
\end{definition}

\begin{definition}[$k$-arc]
A set $\mathcal{S}\subset PG(n,q)$ is called a \emph{$k$-arc} (or just \emph{(projective) arc}) if $|S|=n$ and no $d+1$ points of $S$ lie in a common hyperplane.
A set $\mathcal{S}'\subset \field_q^{n+1}$ such that $\{\lin\{s\}:s\in\mathcal{S'}\}$ is a projective $k$-arc is called an \emph{affine $k$-arc} if 
\end{definition}

\begin{definition}[generic and central generic hyperplane arrangement]
An arrangement $\mathcal{A}$ of hyperplanes in $\field_q^{k-1}$ is called \emph{generic} if for distinct hyperplanes $H_i\in\mathcal{A}$ ($i=1,\ldots,l$, $l\in\nats$) it holds that $\codim_{\aff}\intersection\{H_i:i=1,\ldots,l\}=l$ if $l\leq k-1$ and $\intersection\{H_i:i=1,\ldots,l\}=\emptyset$ otherwise.
Similarly, $\mathcal{A}$ is called a \emph{central generic} arrangement if for distinct hyperplanes $H_i\in\mathcal{A}$ ($i=1,\ldots,l$, $l\in\nats$) it holds that $\codim_{\aff}\intersection\{H_i:i=1,\ldots,l\}=l$ if $l\leq k-1$ and $\intersection\{H_i:i=1,\ldots,l\}=\{0\}$ otherwise.
\end{definition}

We shortly demonstrate that fact.
A linear MDS code $\mathcal{C}$ is given by its check matrix $H(\mathcal{C})\in\field^{(n-k)\times n}_q$ (that is a fully ranked matrix $H$ such that $\ker H=\mathcal{C}$). The property of $\mathcal{C}$ being MDS is equivalent to the property of $H(\mathcal{C})$ having no $d-1=n-k$ linearly dependend columns. Thus, any $(n-k)\times(n-k)$ submatrix of $H(\mathcal{C})$ must be regular. It is then clear, that if we choose the first $(n-k)$ vectors as a basis of $\col(H(\mathcal{C}))$ and rewrite the corresponding operator of $H$ in that basis, we obtain a matrix $H'=(I_{n-k}|M)$ where $M$ is totally regular. Of course we can also start form $M$ and construct a check matrix $H'$ of an MDS code in that manner. 
Interpreting the one-dimensional subspaces of the columns of the check matrix $H(\mathcal{C})$ as elements of the projective space $\proj(\row(H(\mathcal{C}))\iso PG(d-2,q)$ gives us an arc of size $n$ (we can also construct $H(\mathcal{C})$ from that arc).
Starting from a $k$-arc $\mathcal{S}$ in $PG(n,q)$ we can get a central generic arrangement $\mathcal{A}$ of hyperplanes by interpreting the elements of $\mathcal{S}$ as (nonzero) linear functionals $\mathcal{F}$ in $\field_q^{n+1*}$ (which can be chosen up to scalar factor). Then $\mathcal{A}:=\{\ker(f):f\in \mathcal{F}\}$ is the associated central generic arrangement.
Finally, we can get an (affine) generic arrangement from a central generic one by a deconing construction. If $P_{\mathcal{A}}(x_0,\ldots,x_n)=\prod_{f\in\mathcal{F}}{f(X)}\in\field_q[x_1,\ldots,x_{n+1}]$ is the defining polynomial of $\mathcal{A}$ (where $\{x_i:i=1,\ldots,n\}$ is a basis of $\field_q^{n+1}$) then the affine generic arrangement $\mathcal{A}^{\aff}$ arising from that by deconing $\mathcal{A}$ has defining polynomial $P_{\mathcal{A}^{\aff}}(x_1,\ldots,x_n)=P_{\mathcal{A}}(1,x_1,\ldots,x_n)$ (that is the intersection of the hyperplanes in $\mathcal{A}$ with the one given by $x_0=1$).

\begin{conjecture}[main conjecture on MDS codes, $k$-arcs, generic arrangements in $\field_q^d$]
Let $\mathcal{S}$ be an arc in $PG(d,q)$ then $\abs{\mathcal{S}}\leq m(d,q)$ where
\begin{equation}
m(d,q):=\begin{cases}
d+2 :& d \geq q\\
q+2 :& d<q \lgand d\in\{2,q-1\} \lgand 2|q\\
q+1 :& \text{otherwise}
\end{cases}\text{.}
\end{equation} 
Equivalently, in $\field_q^d$ a generic arrangement $\mathcal{A}$ satisfies $\abs{A}\leq m(d-1,q)-1$ or and linear $(n,k)$-code which is MDS over $\field_q$ satisfies $n\leq m(k-1,q)$.
\end{conjecture}

-----------------------------------OLD STUFF---------TO BE DELETED-------------------------------------------------------------------------

\subsection{Connection between generic and central generic arrangements}

There is a fairly natural connection between generic and central generic arrangements, namely that any central generic arrangement is the cone of a generic one and conversely any generic arrangement can be obtained deconing a central generic arrangement.

Now let $\mathcal{A}$ be a generic arrangement of $n$ hyperplanes in the $l$-dimensional vector space $V$ and let $\cone{\mathcal{A}}$ the corresponding central generic arrangement.

For our purposes the \textsc{Poincaré} polynomials of these arrangements are of special interest.
In the case of the generic arrangement $\mathcal{A}$ one has $\mu(X)=(-1)^{r(X)}$ for $X\in L(\mathcal{A})$ and the sets $\{X\in L(\mathcal{A}):r(X)=k\}$ have the cardinality $\binom{n}{k}$. Thus one obtains
\begin{equation}
\pi(\mathcal{A},t)=\sum_{k=0}^n{\binom{n}{k}t^k}\text{.}
\end{equation}

By the above and a well-known fact it follows for the corresponding central generic arrangement that
\begin{equation}
\pi(\cone{\mathcal{A}},t)=(1+t)\pi(\mathcal{A},t)=(1+t)\sum_{k=0}^n{\binom{n}{k}t^k}\text{.}
\end{equation}

% some stuff that did not make that much sense

%\begin{definition}[degradation] Let $\mathcal{A}$ be an arrangement and $X\in L(\mathcal{A})$. %Then define the \emph{degradation} of $X$ as $d(X):=\abs{\{H\in\mathcal{A}:X\geq H\}}-r(X)$. %Moreover, for $c\in \mathcal{C}_m(\mathcal{A})$ define $d(c):=d(\aff(c))$.
%\end{definition}

%\begin{remark} 
%The degradation 'measures' the difference of the number of hyperplanes containing $X$ in %$\mathcal{A}$ and the essential number of hyperplanes to generate $X$. Of course $X$ is uniquely %representable if and only if $d(X)=0$
%\end{remark}

\subsection{Usage of the generalizing statement for the discrete case}

We will now apply these nice results to the problem of the existence of generic arrangements.

To check whether certain triples $(q,l,n)$ can be excluded we want to check whether the values of the expressions for the number of points in $C_m(\mathcal{A})$ make sense.

The \textsc{Poincaré} polynomial of a generic arrangement in $GF(q)^l$ of $n$ hyperplanes is given by

\begin{equation}
\pi(\mathcal{A},t)=\sum_{i=0}^l{\binom{n}{i}t^i}\text{.}
\end{equation}

As this type of polynomials will be the subject of consideration for the next lines we define

\begin{equation}
P_i^j(t):=\sum_{k=0}^i{\binom{j}{k}t^k}\text{.}
\end{equation}

If $\mathcal{A}$ is a generic arrangement corresponding to the triple $(q,l,n)$ (where $l<n$, otherwise it is boring) then any subarrangement consisting of $\tilde{n}$ hyperplanes is also generic (and of the type $(q,l,\tilde{n})$ where $\tilde{n}\leq n$). Let $\tilde{\mathcal{A}}$ be any such subarrangement of $\mathcal{A}$ with $r(\tilde{\mathcal{A}})=\tilde{n}$ (number of hyperplanes as $\tilde{A}$ is generic). Then the identities

\begin{equation}
0 \leq \abs{C_m(\tilde{\mathcal{A}})} \leq q^l \text{ for } 0\leq m\leq\tilde{n}\text{.}
\end{equation}

must hold for $\tilde{n}=0,\ldots,n$. Translating this to the \textsc{Poincaré} polynomials one gets the necessary conditions

\begin{align}
0\leq q^{l-m}\frac{\pi^{(m)}(\tilde{\mathcal{A}},-q^{-1})}{m!} \leq q^l \text{ for } 0\leq m\leq\min\{l,\tilde{n}\}
\end{align}

where $\tilde{n}=0,\ldots,n$. It is now obvious that the first inequality implies the second ($\leq q^l$) as

\begin{equation}
\sum_{m=0}^{\tilde{n}}{q^{l-m}\frac{\pi^{(m)}(\tilde{\mathcal{A}},-q^{-1})}{m!}}=\pi(\tilde{\mathcal{A}},0)q^l=q^l
\end{equation}

and thus if all summands are greater or equal to zero, each of them must satisfy the second inequality. Another important fact is that

\begin{equation}
\pi^{(m)}(\tilde{\mathcal{A}},-q^{-1})=\tilde{n}\cdots(\tilde{n}-m+1)P_{l-m}^{\tilde{n}-m}(t)
\end{equation}
for $m=0,\ldots,\min\{\tilde{n},l\}$. Moreover, one can omit the cases where $\tilde{n}\leq n$ because then $P_{l-m}^{\tilde{n}-m}(-q^{-1})=(1-q^{-1})^{\tilde{n}-m}>0$ for $m=0\ldots,\tilde{n}$.

Thus rewrite the condition for $q$ as

\begin{equation}
P_i^j(q^{-1})\geq 0 \text{ for } j=l+1,\ldots,n \text{ and } j-i\leq n-l\text{.}
\end{equation}

We will see that these inequalities are equivalent with $q\geq l-n+1$.

At first an easy fact about $P_i^j$

\begin{lemma}
Let $j>i\geq 0$ ($j>1$) then $P_i^j$ is monotone on $[0,1]$ and has a single zero in $(0,1)$ if $i$ is odd.
If $i$ is even, $P_i^j$ is strictly positive on $[0,1]$.
\end{lemma}

\begin{proof}
The proof is simple and happens by induction on $i$. For $i=0$ the statement is obvious as $P_0^j(t)=1>0$.

Assume the statement holds for all $i<k$. 
\paragraph{Case where $k$ is odd:}
Then for $P_k^j$ we have $P_k^j(0)=1$ and
\begin{equation}
P_k^j(1)=\sum_{\nu=0}^{\frac{k-1}{2}}{\left(\binom{j}{2\nu}-\binom{j}{2\nu+1}\right)}
\end{equation}
Now, if $k\leq \ceil{j/2}$ all summands are non-positive and the first is negative as $j>1$. In the opposite case, we use that $P_k^j(1)=-(-1)^jP_{j-k-1}^j(1)$. By induction hypothesis we have that $\sgn(P_{j-k}^j(1))=(-1)^{j-k-1}$. Thus obtain $P_k^j(1)=-(-1)^j(-1)^{j-k-1}=(-1)^k$ as desired. Moreover, by induction hypothesis $P_k^j$ is strictly decreasing as $\frac{\d}{\d t}P_k^j(t)=-jP_{k-1}^{j-1}(t)<0$. Thus $P_k^j$ has a single zero in $(0,1)$.
\paragraph{Case where $k$ is even:} In this case we have that $P_k^j(0)=1>0$ and $P_k^j(1)>0$ (by similar argument as in the previous case). Assume $P_k^j$ attains its minimum in $\xi\in(0,1)$ (otherwise we are done as it is positive on $0$ and $1$. Then its derivative $\frac{\d}{\d t}P_k^j(\xi)=-jP_{k-1}^{j-1}(\xi)=0$. It is obvious that

\begin{equation}
P_k^j(t)=\sum_{\nu=0}^k{\binom{j}{\nu}(-t)^\nu}=\sum_{\nu=0}^{k-1}{\binom{j-1}{\nu}(-t)^\nu}-t\sum_{\nu=0}^{k-1}{\binom{j-1}{\nu}(-t)^\nu}+\binom{n-1}{k-1}(-t)^k
\end{equation}

from which we deduce that $P_k^j(\xi)=\binom{n-1}{k-1}(-\xi)^k>0$. Thus we are done with the proof.
\end{proof}

Using this lemma, it is now clear that we are searching for the smallest zero $\xi$ of the polynomials $P_i^j$ for $j=l+1,\ldots,n$ and $j-i\leq n-l$ in $[0,1]$ where we can drop the even $i$ as the corresponding polynomials have no zeros in this interval. 

Next, we find some monotony among these zeros.

\begin{lemma}
Let $\xi\in(0,1)$ and $j>i\geq 0$ and $i$ be odd such that $P_i^j(\xi)=0$. Then $P_{i+2}^j(\xi)>0$ and thus the unique zero of $P_{i+2}^j$ must be greater than $\xi$.
\end{lemma}

\begin{proof}
Write $P_i^j$ as
\begin{equation}
P_i^j(t)=\sum_{\nu=0}^{\frac{i-1}{2}}{t^{2\nu}\left(\binom{j}{2\nu}-\binom{j}{2\nu+1}t\right)}\text{.}
\end{equation}
Note when $t\in[0,1]$ the summands $t^{2\nu}\left(\binom{j}{2\nu}-\binom{j}{2\nu+1}t\right)$ negative if and only if $t>\frac{2\nu+1}{j-2\nu}$ or equivalently $\nu<\frac{jt-1}{2(t+1)}$. Thus if $P_i^j(\xi)=0$ we must have $P_{i+2}^j(\xi)>0$ as then the index $\nu$ is already 'to big'.
This proves (with the previous lemma) that the unique zero of $P_{i+2}^j$ is greater than $\xi$.
\end{proof}

Thus it follows that the smallest zero among the the polynomials $P_i^j$ for $j=l+1,\ldots,n$, $j-i\leq n-l$ in $[0,1]$ is $\frac{1}{n-l+1}$ (the zero of $P_1^{n-l+1}$).

Our final result is now

\begin{lemma} Let $\mathcal{A}$ be a generic arrangement corresponding to the triple $(q,l,n)$. Then $q\leq n-l+1$. Similarly, if $\mathcal{A}$ is a central generic arrangement and $l\geq 2$ then the same inequality holds.
\end{lemma}

\begin{proof}
The proof was already given.
\end{proof}

---------------------------------------END OLD STUFF--------------------------------------------------------------------------

\section{$k$-arcs and the main conjecture}

\section{Segre's lemma of tangents}

\begin{lemma}[Segre's lemma of tangents]
Let $d\geq3$ and $S$ be an arc in $\field_q^d$. Then for pairwise distinct $x_i\in S$ ($i=1,2,3$) and $X\subset S\setminus\{x_1,x_2,x_3\}$, $\abs{X}=d-3$ we have
\begin{equation}
T_{X\setjoin\{x_1\}}(x_2)T_{X\setjoin\{x_2\}}(x_3)T_{X\setjoin\{x_3\}}(x_1)=(-1)^{t+1}T_{X\setjoin\{x_2\}}(x_1)T_{X\setjoin\{x_3\}}(x_2)T_{X\setjoin\{x_1\}}(x_3)
\end{equation}
where $T_Y$ is the tangent polynomial (defined up to scalar factor in $\field_q^*$ and $t=\deg(T_Y)=q+d-1-\abs{S}$ for any $Y\subset S$ of size $d-2$.
\end{lemma}

\begin{proof}
... 
\end{proof}

Later we will do some calculations with the polynomials $T_Y$ for $Y\in\binom{S}{d-2}$. Thus it is desirable to choose the scalar factors in front of each of them in an appropriate way to simplify the calculation.

\begin{lemma}
Let $S$ be an arc in $\field_q^d$ ($d\geq 3$) and $<$ some linear
order on $S$. Then we can define the tangent polynials $T_Y$
($Y\subseteq S$, $\abs{Y}=d-2$) such that for all $x_1,x_2,X$ we have
\begin{equation}
\frac{T_{X\setjoin\{x_2\}}(x_1)}{T_{X\setjoin\{x_1\}}(x_2)}=\left(\frac{\sgn(X\setjoin\{x_2\},x_1)}{\sgn(X\setjoin\{x_1\},x_2)}\right)^{t+1}
\end{equation}
where $X\subseteq S$ has $d-3$ elements and $x_1,x_2\in S\setminus X$ are distinct.
\end{lemma}

\begin{remark}
Here, by $(A_1,\ldots,A_n)$ we mean the tuple
which is given by writing down the elements of $A_1,\ldots,A_n$
where each $A_i$ is written down in the order $<$
($i\in\{1,\ldots,n\}$). Moreover, by $\sgn(A_1,\ldots,A_n)$ we mean
the sign of the permutation which corresponds to the tuple $(A_1,\ldots,A_n)$
where the identity is given by $(\union_{i=1}^n{A_i})$. To abbreviate notation, for $A_i$ a singleton we just write its
element without curly brackets.  
This convention shall be used in the following.
\end{remark}

\begin{proof}
We define the directed graph $G=(V,E)$ by $V:=\binom{S}{d-2}$ and $E:=\{(u,v)\in V^2:\abs{u\setminus v}=1\}$ (although $E$ as a relation is symmetric, $G$ shall be seen as a directed graph).
Moreover, we define a labeling $\lambda:E\to \field_q^*$. For $(u,v)\in E$ let $u_v\in u\setminus v$ and $v_u\in v\setminus u$ be the elements of the singletons. Then 
\begin{equation}
\lambda(u,v):=\frac{T_u(v_u)}{T_v(u_v)}\text{.} 
\end{equation}
Then in the two types of triangles in $G$ we have two different relations that hold.
The first type of triangles consists of vertices $u,v,w\in V$ such that $\abs{u\setjoin v\setjoin w}=d-1$.
Here it clearly holds that
\begin{equation}
\lambda(u,v)\lambda(v,w)\lambda(w,u)=1
\end{equation}
which is simply a tautology when replacing $\lambda$ by its definition.
In the second type of triangles consisting of vertices $u,v,w\in V$ such that $\abs{u\setjoin v\setjoin w}=d$ we have
\begin{equation}
\lambda(u,v)\lambda(v,w)\lambda(w,u)=(-1)^{t+1}
\end{equation}
which turns out to be just a reformulation of Segre's lemma of tangents.
Now it is clear, that $\lambda$ is uniquely defined by any restriction $\rest{\lambda}_{E_T}$ where $T(V,E_T)$ is a (directed) rooted spanning tree of $G$ with root $r\in V$ (by the above relations in triangles of $G$ and as $G$ is obviously strongly connected).
Moreover, when replacing $T_u$ by $\tilde{T}_u:=\mu T_u$ one just modifies $\lambda$ to $\tilde{\lambda}$ where 
\begin{equation}
\tilde{\lambda}(v,w)=\begin{cases} 
\lambda(v,w) & : u\notin\{v,w\}\\
\mu\lambda(v,w) &: v=u\\
\mu^{-1}\lambda(v,w) &: w=u
\end{cases}\text{.}
\end{equation}
This idea can be used to modify the tangent polynomials step by step to achieve any values of $\lambda$ among $E_T$.
This can be done as follows. Define the sets $V_l:=\{v\in V: \text{the shortest path from } r \text{ to } v \text{ is of length } l\}$ ($l\in\nats$). Since $G$ is finite there is some $L\in\nats$ such that $\{V_l:l\in\{0,\ldots,L\}\}$ is a partition of $V$. Moreover, one notes that the sets $E_l:=\{(u,v)\in E_T:u\in V_{l-1},v\in V_l\}$ for $l=1,\ldots,L$ form a partition of $E_T$. Thus one can modify the labeling $\lambda$ at first on $E_1$ then on $E_2$ etc. As there is no edge in $T$ between the sets $V_m$ and $V_n$ where $\abs{n-m}\geq 2$ this procedure works and one does not destroy former changes on some $E_i$. 
This shows that $\lambda$ can be changed to any labeling satisfying the two triangle conditions.
At last we check that these are satisfied for the labeling $\bar{\lambda}$ given in the lemma, where for $(u,v)\in E$

\begin{equation}
\bar{\lambda}(u,v):=\left(\frac{\sgn(u,v_u)}{\sgn(v,u_v)}\right)^{t+1}\text{.}
\end{equation}

For a triangle $uvw$ of the first type ($\abs{u\setjoin v\setjoin w}=d-1$) we obtain $v_u=w_u$, $u_v=w_v$, $u_w=v_w$ (with the same notation as before) and thus one gets
\begin{align}
\bar{\lambda}(u,v)\bar{\lambda}(v,w)\bar{\lambda}(w,u) & =\left(\frac{\sgn(u,v_u)}{\sgn(v,u_v)}\frac{\sgn(v,w_v)}{\sgn(w,v_w)}\frac{\sgn(w,u_w)}{\sgn(u,w_u)}\right)^{t+1}\\
& =1\text{.}
\end{align}
Similarly, for a triangle $uvw$ of the second type ($\abs{u\setjoin v\setjoin w}=d$) one gets the desired identity by the following reasoning. W.l.o.g. we may write $u=X\setjoin\{x_1\}$, $v=X\setjoin\{x_2\}$, $w=X\setjoin\{x_3\}$ for a $(d-3)$-element set $X:=u\setmeet v\setmeet w$ and elements $x_i\in S$ ($i=1,2,3$) such that $\{x_1,x_2,x_3\}\setjoin X=u\setjoin v\setjoin w$. Furthermore we may assume that $X^1<x_1<X^2<x_2<X^3<x_3<X^4$, where $X^1,X^2,X^3,X^4$ partitions $X$ (otherwise we interchange the labeling of $u$, $v$ and $w$). Then we may compute

\begin{align}
\bar{\lambda}(u,v)\bar{\lambda}(v,w)\bar{\lambda}(w,u) 
& = \left(\frac{\sgn(X^1,x_1,X^2,X^3,X^4,x_2)}{\sgn(X^1,X^2,x_2,X^3,X^4,x_1)}\right)^{t+1}\\
& \times \left(\frac{\sgn(X^1,X^2,x_2,X^3,X^4,x_3)}{\sgn(X^1,X^2,X^3,x_3,X^4,x_2)}\right)^{t+1}\\
& \times \left(\frac{\sgn(X^1,X^2,X^3,x_3,X^4,x_1)}{\sgn(X^1,x_1,X^2,X^3,X^4,x_3)}\right)^{t+1}\\
& = (-1)^{((|X^3|+|X^4|)+(|X^2|+1+|X^3|+|X^4|))(t+1)}\\
& \times (-1)^{(|X^4|+(|X^3|+1+|X^4|)(t+1)}\\
& \times (-1)^{((|X^2|+|X^3|+1+|X^4|)+|X^4|)(t+1)}\\
& = (-1)^{t+1}
\end{align}

which finishes the proof.
\end{proof}

This lemma enables us now to make the following definition

\begin{definition}
Let $S\subseteq\field_q^d$ be an arc. We say that its tangent polynomials are defined canonically with respect to the linear order $<$ on $S$ if they satisfy for all $x_1,x_2,X$ the identity
\begin{equation}
\frac{T_{X\setjoin\{x_2\}}(x_1)}{T_{X\setjoin\{x_1\}}(x_2)}=\left(\frac{\sgn(X\setjoin\{x_2\},x_1)}{\sgn(X\setjoin\{x_1\},x_2)}\right)^{t+1}
\end{equation}
where $X\subseteq S$ has $d-3$ elements and $x_1,x_2\in S\setminus X$ are distinct.
\end{definition}

\begin{remark}
This simple but effective trick enables us to prove some results of \textsc{Ball} and \textsc{de Beule} in a much simpler way.
Note that in the above definition the tangent polynomials are still only defined up to scalar factor, but their quotients are fixed.
In the following we do only work with the tangent polynomials defined in that manner.
\end{remark}

\section{The polynomials $Q(X)$ and $P(X)$}

The previous section enables us to state the following lemma

\begin{lemma}[the Segre polynomial]
Let $S$ be an arc in $\field_q^d$ and $T_X$ its tangent polynomials
defined canonically with respect to some linear order $<$ (for
$X\subseteq S$, $\abs{X}=d-2$). Furthermore, let $d+t-1\leq
\abs{S}$. Then there exists a unique polynomial $Q(X)\in
\symalg(\extpow^{d-1}(\field_q^d)^*)$ such that
\begin{enumerate}
\item The polynomial $Q(X)$ is homogeneous of degree $t$.
\item It holds that $Q(x_1\wedge\ldots\wedge
  x_{d-1})=T_{x_1,\ldots,x_{d-2}}(x_{d-1})$ for $x_i\in S$
  ($i\in\{1,\ldots,n\}$) and $x_i<x_j$ for $i<j$.
\end{enumerate}

Moreover, $Q(X)$ does not depend on the order $<$ up to scalar factor.
The polynomial $P(X)=P(X_1,\ldots,X_{d-1}):=Q(X_1\wedge\ldots\wedge
X_{d-1})$ then satisfies

\begin{enumerate}
\item For all $A\subseteq S$, $\abs{A}=d-1$ and any permutation $\pi\in\symgr{A}$
\begin{align}
P(A^\pi)=T_{A^\pi\setminus\{a\}}(a)\sgn(A\setminus\{a^{\pi^{-1}}\},a^{\pi^{-1}})^{t+1}\sgn(\pi)^t\text{.}
\end{align}
where $a$ is the biggest element in $A$.
\item The polynomial $P(X)=P(X_1,\ldots,X_{d-1})$ is homogenous of
  degree $t$ in each component $X_i$.
\end{enumerate}
Moreover, the polynomial $P(X)$ satisfies $P(a_1,\ldots,a_{d-1})=0$ if
$a_1,\ldots,a_{d-1}$ are linear dependent.
\end{lemma}

\begin{proof}
We can construct $S$ by the following interpolation idea. Take
$B\subseteq S$ such that $\abs{B}=d+t-1$. Then set
\begin{align}
\tilde{P}(X):=\sum_{\substack{A'\subseteq B\\
    \abs{A'}=d-1}}{T_{A'\setminus\{\bigjoin{A'}\}}\left(\bigjoin{A'}\right)\prod_{z\in
    B\setminus A'}{\frac{\det(z,X)}{\det(z,A')}}}\text{.}
\end{align}
At first we verify that $\tilde{P}$ satisfies the conditions of the
lemma. For $A\subseteq B$, $\abs{A}=d-1$ and $\pi\in\symgr{A}$, $a$, $a^{\pi^{-1}}$
the last element of $(A)$ and $(A^\pi)$, respectively, we get
\begin{align}
\tilde{P}(A^\pi)
 &= T_{A^\setminus\{a\}}(a)\sgn(\pi)^t\\
 &= T_{A^\pi\setminus\{a^{\pi^{-1}}\}}(a^{\pi^{-1}})\sgn(A^\pi\setminus\{a^{\pi^{-1}}\},a^{\pi^{-1}})\sgn(\pi)^t
\end{align}
as desired. To prove this identity for $A\subseteq S$, $\abs{A}=d-1$,
we argue by induction on $r:=\abs{A\setminus B}$. For $r=0$ we have
already proven the claimed identity. Assume it was proven for $r$ and
let $\abs{A\setminus B}=r+1$. Then pick $s\in A\setminus B$.
\end{proof}

\section{Interpolation formulas}

An elementary but particularly nice idea is to use interpolation
formulas to capture information about the arc.

There are two basic possibilities to apply interpolation. 

\begin{lemma}[interpolation of the tangent polynomial]
Let $S$ be an arc in $\field_q^d$ and $A,B\subseteq S$ be disjoint subsets with
$\abs{A}=t+2$ and $\abs{B}=d-2$. It then holds that
\begin{align}
\sum_{a\in A}{T_{B}(a)\prod_{z\in A\setminus \{a\}}\det(z,B,a)^{-1}} =0
\end{align}
or equivalently when the tangent polynomials are defined canonically
with respect to the order $<$
\begin{align}
\sum_{a\in A}{P(\{a\}\setjoin B)\prod_{z\in A\setminus\{a\}}\det(z,\{a\}\setjoin B)^{-1}}=0\text{.}
\end{align}
\end{lemma}

\begin{proof}
As $T_B(x+y)=T_B(x)$ for all $x\in\field_q^d$ and $y\in\lin{B}$ we may
interpolate the polynomial $\overline{T}_B(X):=T_{B}(X+\lin{B})$ as a homogenous polynomial of
degree $t$ in $\field_q^d/\lin{B}$. To do this, pick $a\in A$ to get
\begin{align}
T_B(x)=\sum_{a'\in A\setminus\{a\}}{T_B(a')\prod_{z\in A\setminus\{a,a'\}}{\frac{\det(z,B,x)}{\det(z,B,a')}}}
\end{align}
since both sides are functions of polynomials in $x$ of degree $t$
and both are constant on cosets of $\lin{B}$ and agree on $t+1$
linearly independent points of $\field_q^d/\lin{B}$ (namely $\overline{a}'$
for $a'\in A\setminus\{a\}$). Replacing $x$ by $a$ and dividing by
$\prod_{z\in A\setminus\{a\}}{\det(z,B,a)}$ one gets 
\begin{align}
T_B(a)\prod_{z\in  A\setminus\{a\}}{\det(z,B,a)} 
 &= \det(a',B,a)^{-1}\sum_{a'\in A\setminus\{a\}}{T_B(a')\prod_{z\in A\setminus\{a,a'\}}{\det(z,B,a')^{-1}}}
\end{align}
which is what we wanted to prove.
The second formulation only uses the definition of $P$.
\end{proof}

The second idea is to interpolate the determinants themselves

\begin{lemma}[interpolation of determinants]
Let $A,B,C\subseteq \field_q^d$ such that $\lin(A\setjoin
C)=\field_q^d$, $\abs{A}+\abs{C}=d+1$ and $\abs{B}+\abs{C}=d-1$ and $<$
be some linear order on $A$. Then it holds that
\begin{align}
\sum_{a\in A}{\sgn(a,A\setminus\{a\})\det(a,B,C)\det(A\setminus\{a\},C)}=0\text{.}
\end{align}
Here, $\sgn$ is taken with respect to $<$.
\end{lemma}

\begin{proof}
Picking $a\in A$ and interpolating $\det(\cdot,B,C)$ as a linear form in
$\field_q^d/\lin{C}$ gives
\begin{align*}
\det(x,B\setjoin C) 
 &= \sum_{a'\in A\setminus\{a\}}{\det(a',B,C)\frac{\det(x,A\setminus\{a,a'\},C)}{\det(a',A\setminus\{a,a'\},C)}}
\end{align*}
which holds as it holds for $x$ an element of the basis $\bar{a}'$ for $a'\in
A\setminus\{a\}$ of $\field_q^d/\lin{C}$. Replacing $x$ by $a$ and
rearranging the terms yields
\begin{align*}
\det(a,B,C)\det(A\setminus\{a\},C)
 &= 
\sum_{a'\in A\setminus\{a\}}{\det(a',B,C)\frac{\det(a,A\setminus\{a,a'\},C)}{\sgn(a',A\setminus\{a,a'\})}}\\
 &= 
\sum_{a'\in A\setminus\{a\}}{\det(a',B,C)\det(A\setminus\{a'\},C)\frac{\sgn(a,A\setminus\{a,a'\})}{\sgn(a',A\setminus\{a,a'\})}}\\
 &= 
-\sum_{a'\in A\setminus\{a\}}{\det(a',B,C)\det(A\setminus\{a'\},C)\frac{\sgn(a',A\setminus\{a'\})}{\sgn(a,A\setminus\{a\})}}
\end{align*}
which is the desired result.
\end{proof}

\subsection{Manipulation of interpolation identities}

Now, the idea is to play with the interpolation identities to reach a
contradiction in the case where $t= d-3$ (i.e. $\abs{S}=q+2$).

\paragraph{First attempt.}

\begin{lemma}[\textsc{Ball} \& \textsc{de Beule}'s $ABC$-lemma]
Let $S$ be an arc in $\field_q^d$ ($p=\rchar{\field_q}$) and let
$P(X)$ be its \textsc{Segre}-polynomial with respect to the order $<$. Let $0\leq
r\leq\min\{d,p\}-1$ and $A,B,C\subseteq S$ disjoint sets such
that $\abs{A}+\abs{B}=r+t+1$, $\abs{C}=d-1-r$. Then it holds that
\begin{align*}
 &(-1)^r\sum_{\substack{A'\subseteq A\\ \abs{A'}=r}}{P(A'\setjoin C)\prod_{z\in (A\setminus A')\setjoin B}{\det(z,A'\setjoin C)^{-1}}}\\
 &= \sum_{\substack{B'\subseteq B\\ \abs{B'}=r}}{P(B'\setjoin C)\prod_{z\in (B\setminus B')\setjoin A}{\det(z,B'\setjoin C)^{-1}}}\text{.}
\end{align*}
\end{lemma}

\begin{proof}
The proof happens by induction on $r$. For $r=0$ the statement is a
tautology.
Now, suppose the lemma is proven for $r-1\geq 0$ and let
$r\leq\min\{d,p\}-1$.
Moreover, let $A,B,C\subseteq S$ be disjoint sets such
that $\abs{A}+\abs{B}=r+t+1$, $\abs{C}=d-1-r$. Then pick $a\in A$ and
apply the lemma for $r-1$ and sets $A\setminus\{a\}$, $B$,
$\{a\}\setjoin C$ (w.l.o.g. we may assume that $A$ or $B$ is not empty
- and their roles are symmetric).
This yields
\begin{align*}
 &(-1)^{r-1}\sum_{\substack{A'\subseteq A\setminus\{a\}\\ \abs{A'}=r-1}}{P(A'\setjoin\{a\}\setjoin C)\prod_{z\in (A\setminus A')\setjoin B}{\det(z,A'\setjoin\{a\}\setjoin C)^{-1}}}\\
 &= \sum_{\substack{B'\subseteq B\\ \abs{B'}=r-1}}{P(B'\setjoin\{a\}\setjoin C)\prod_{z\in (B\setminus B')\setjoin A\setminus\{a\}}{\det(z,B'\setjoin\{a\}\setjoin C)^{-1}}}\text{.}
\end{align*}
Now, we sum this over $a\in A$ to get
\begin{align*}
 &(-1)^{r-1}r\sum_{\substack{A'\subseteq A\\ \abs{A'}=r}}{P(A'\setjoin C)\prod_{z\in (A\setminus A')\setjoin B}{\det(z,A'\setjoin C)^{-1}}}\\
 &= \sum_{\substack{B'\subseteq B\\ \abs{B'}=r-1}}{\sum_{a\in A}{P(B'\setjoin\{a\}\setjoin C)\prod_{z\in (B\setminus B')\setjoin A\setminus\{a\}}{\det(z,B'\setjoin\{a\}\setjoin C)^{-1}}}}\\
 &= \sum_{\substack{B'\subseteq B\\ \abs{B'}=r-1}}{\sum_{a\in A}{P(B'\setjoin\{a\}\setjoin C)\prod_{z\in (B\setminus B'\setjoin A)\setminus\{a\}}{\det(z,B'\setjoin\{a\}\setjoin C)^{-1}}}}\\
 &= -\sum_{\substack{B'\subseteq B\\ \abs{B'}=r-1}}{\sum_{b\in B\setminus B'}{P(B'\setjoin\{b\}\setjoin C)\prod_{z\in(B\setminus B'\setjoin A)\setminus\{b\}}{\det(z,B'\setjoin\{b\}\setjoin C)^{-1}}}}\\
 &= -r\sum_{\substack{B'\subseteq B\\ \abs{B'}=r}}{P(B'\setjoin C)\prod_{z\in (B\setminus B')\setjoin A}{\det(z,B'\setjoin C)^{-1}}}\text{.}
\end{align*}
Here we used the interpolation of tangent polynomials in the fourth
line for the sets $B'\setjoin C$ and $B\setminus B'\setjoin A$ when
$r-1\leq\abs{B}$. In the case $\abs{B}< r-1$ the LHS is zero (as it
had been zero before).
If $r\leq p-1$ it is a unit and we can divide the above by $-r$ to complete
the induction.
\end{proof}

\begin{corollary}[the case $d\leq p$]
If $d\leq p$ then $\abs{S}\leq q+1$.
\end{corollary}

\begin{proof}
Assume that $d\leq p$ and $\abs{S}\geq q+2$ or equivalently $t\leq
d-3$. Then apply \textsc{Ball \& de Beule}'s $ABC$-lemma with $r=d-1$,
$\abs{A}=d-1$ and appropriate subsets $B$, $C$ (using dualisation of
the arc we may assume w.l.o.g. that $d+t\leq 2d-3\leq\abs{S}$). Then
we have that $\abs{B}=t+1\leq d-2$ and thus the lemma gives
\begin{align*}
(-1)^{d-1}P(A)\prod_{z\in B}{\det(z,A)^{-1}}=0
\end{align*}
which is a contradiction.
\end{proof}

\begin{remark}
This is as we will see the optimal result using only the interpolation
of the tangent polynomial.
\end{remark}

\begin{lemma}[the subset-lemma] 
Let $S$ be an arc in $\field_q^d$ ($p=\rchar{\field_q}$) and let
$P(X)$ be its \textsc{Segre}-polynomial with respect to the order
$<$. Let $0<r\leq\min\{d,p\}-1$ and $A,B,C\subseteq S$ disjoint sets
such that $\abs{A}+\abs{B}=r+t+1$, $\abs{C}=d-1-r$ then
\begin{align}
0 &= \sum_{\substack{A'\subseteq A, B'\subseteq B\\
     \abs{B'}+\abs{A'}=r}}{P(A'\setjoin B'\setjoin C)\prod_{z\in
     (B\setminus B')\setjoin (A\setminus A')}{\det(z,A'\setjoin B'\setjoin C)^{-1}}}
\end{align}
\end{lemma}

\begin{proof}
Let $A,B,C\subseteq S$ disjoint sets such
that $\abs{A}+\abs{B}=r+t+1$, $\abs{C}=d-1-r$. Then pick $A''\subseteq
A$ and apply \textsc{Ball \& de Beule}'s $ABC$-lemma to
$r-\abs{A''}$ and sets $A\setminus A''$, $B$ and $C\setjoin A''$ to
obtain
\begin{align}
 &(-1)^{r-\abs{A''}}\sum_{\substack{A'\subseteq A\setminus A''\\
     \abs{A'}=r-\abs{A''}}}{P(A'\setjoin A''\setjoin C)\prod_{z\in
     (A\setminus (A'\setjoin A''))\setjoin B}{\det(z,A'\setjoin A''\setjoin C)^{-1}}}\\
 &= \sum_{\substack{B'\subseteq B\\
     \abs{B'}=r-\abs{A''}}}{P(B'\setjoin A''\setjoin C)\prod_{z\in
     (B\setminus B')\setjoin (A\setminus A'')}{\det(z,B'\setjoin A''\setjoin C)^{-1}}}\text{.}
\end{align} 
Summing over $A''\subseteq A$ yields (where $s=\abs{A''}$ and on the
LHS we replace the symbol $A'\setjoin A''$ by $A'$ and on the RHS the
symbol $A''$ by $A'$)
\begin{align}
 0 &= \sum_{s=0}^r{(-1)^{r-s}\binom{r}{s}}\times\sum_{\substack{A'\subseteq A\\ \abs{A'}=r}}{P(A'\setjoin C)\prod_{z\in
     (A\setminus A')\setjoin B}{\det(z,A'\setjoin C)^{-1}}}\\
 &= \sum_{\substack{A'\subseteq A, B'\subseteq B\\
     \abs{B'}+\abs{A'}=r}}{P(A'\setjoin B'\setjoin C)\prod_{z\in
     (B\setminus B')\setjoin (A\setminus A')}{\det(z,A'\setjoin B'\setjoin C)^{-1}}}
\end{align}
for $r>0$, which is what we intended to prove.
\end{proof}

\paragraph{First attempt.} The first idea we present does only use the interpolation formula of
the tangent polynomials and is due to \textsc{Ball} and
\textsc{de Beule}.

\begin{lemma}[\textsc{Ball} \& \textsc{de Beule}'s initial lemma]
Let $S$ be an arc in $\field_q^d$ ($p=\rchar{\field_q}$) and let $T_X$
($X\in S$, $\abs{X}=d-2$) be its tangent polynomials defined canonically with respect to some linear order $<$. Let $0\leq r\leq\min\{d-2,t+1,p-1\}$ and $A,B,C\subseteq S$ disjoint sets such that $\abs{A}=t+2$, $\abs{B}=d-2-r$ and $\abs{C}=r$. Then it holds that
\begin{equation}
\sum_{\substack{A'\in\binom{A}{r}\\ a'\in A\setminus A'}}{T_{A'\setjoin B}(a')\prod_{z\in A\setminus (A'\setjoin\{a'\})\setjoin C}\det(z,A'\setjoin B,a')^{-1}}=0\text{.}
\end{equation}
Moreover, the expression in the sum does only depend on the sets $A'\setjoin\{a'\}\setjoin B$ and $A\setminus (A'\setjoin\{a'\})\setjoin C$.
\end{lemma}

\begin{proof}
At first we prove the second claim. To do this, pick $a''\in A'$ and
set $A'':=A'\setminus\{a''\}\setjoin\{a'\}$. Then we have by the
definition of the tangent polynomials canonically with respect to $<$ that
\begin{equation}
T_{A'\setjoin B}(a') = \left(\frac{\sgn(A'\setjoin B,a')}{\sgn(A''\setjoin B,a'')}\right)^{t+1}T_{A''\setjoin B}(a'')\text{.}
\end{equation}
But for each factor in the product belonging to $A'$, $a'$ we get similarly
\begin{equation}
\det(z,A'\setjoin B,a')^{-1}=\frac{\sgn(A'\setjoin B,a')}{\sgn(A''\setjoin B,a'')}\det(z,A''\setjoin B,a'')^{-1}\text{.}
\end{equation}
Thus, as there are $t+1$ factors in the product, it is immediate that 
\begin{align*}
T_{A'\setjoin B}(a')\prod_{z\in A\setminus (A'\setjoin\{a'\})\setjoin C}\det(z,A'\setjoin B,a')^{-1} = T_{A''\setjoin B}(a'')\prod_{z\in A\setminus (A''\setjoin\{a''\})\setjoin C}\det(z,A''\setjoin B,a'')^{-1}\text{.}
\end{align*}

Now we prove the lemma by induction on $r$. For $r=0$ it is the interpolation lemma.
To get the induction to work we assume that the lemma holds for $r\geq 0$ and assume $r+1\leq\min\{d-2,t+1,p-1\}$.
Let $A,B,C\subseteq S$ be disjoint with $\abs{A}=t+2$, $\abs{B}=d-3-r$ and $\abs{C}=r+1$. We then pick $a\in A$ and $c\in C$ and assign the lemma for $r$ to
$\tilde{A}:=A\setminus\{a\}\setjoin\{c\}$ and $\tilde{B}:=B\setjoin\{a\}$ and $\tilde{C}:=C\setminus\{c\}$. 
This yields by considering the two cases where $c\in A'\setjoin\{a'\}$ and $c\notin A'\setjoin\{a'\}$ (in the former case we may assume $a'=c$ in the sums using the second claim):
\begin{align}
0 & = (r+1)\sum_{A'\in\binom{\tilde{A}\setminus\{c\}}{r}}{T_{A'\setjoin\tilde{B}}(c)\prod_{z\in \tilde{A}\setminus (A'\setjoin\{b\})\setjoin \tilde{C}}\det(z,A'\setjoin\tilde{B},c)^{-1}}\\
& + \sum_{\substack{A'\in\binom{\tilde{A}\setminus\{b\}}{r}\\ a'\in \tilde{A}\setminus\{b\}\setminus A'}}{T_{A'\setjoin\tilde{B}}(a')\prod_{z\in \tilde{A}\setminus (A'\setjoin\{a'\})\setjoin \tilde{C}}\det(z,A'\setjoin\tilde{B},a')^{-1}}\text{.}
\end{align}
Now, note that we can replace $\tilde{A}\setminus \{c\}$ by $A\setminus\{a\}$ and $\tilde{B}$ by $\{a\}\setjoin B$ in both sums and interchange the roles of $c$ and $a$ in the first sum and $a'$ and $a$ in the second sum (due to the second claim). The whole expression is then
\begin{align}
0 & = (r+1)\sum_{A'\in\binom{A\setminus\{a\}}{r}}{T_{A'\setjoin B\setjoin\{c\}}(a)\prod_{z\in A\setminus (A'\setjoin \{a\})\setjoin\tilde{C}}{\det(z,A'\setjoin B\setjoin\{c\},a)^{-1}}}\\
& + \sum_{A'\distjoin\{a'\}\in\binom{A\setminus\{a\}}{r+1}}{T_{A'\setjoin\{a'\}\setjoin B}(a)\prod_{z\in A\setminus (A'\setjoin\{a'\})\setjoin C}{\det(z,A'\setjoin\{a'\}\setjoin B,a)^{-1}}}\text{.}
\end{align}

Now summing the whole expression over $a\in A$ changes the first sum into $(r+1)$-times the lemma for $r$ and sets $A$, $B\setjoin\{c\}$ and $\tilde{C}$ and thus vanishes by induction. Similarly, the second sum changes into $(r+1)$-times the expression in the lemma for $r+1$ and sets $A$, $B$ and $C$ as there are $r+1$ possibilities to build the ($r+1$)-element set $A'\distjoin\{a'\}$ by $A'$ and $a'$. But as $r+1\leq p-1$, it is a unit mod $p$ and we are done with induction.
\end{proof}

With this, one deduces

\begin{corollary}[the case $d\leq p$]\label{cor:mdsconjpcase}
If $S\subseteq \field_q^d$ is an arc and $d\leq p$ where $p=\rchar{\field_q}$ then $\abs{S}\leq q+1$.
\end{corollary}

\begin{proof}
Assume the contrary. Then we have an arc of cardinality $q+2$. It follows that $t=d-3\leq p-3$. Thus \textsc{Ball}'s \& \textsc{de Beule}'s lemma applies for $r=t+1=d-2$ (using dualisation we can assume $t+d\leq \abs{S}$). But then we have a sum of $r+1$ equal nonzero summands in the lemma.
As $r+1=t+2\leq p-1$ it is a unit und thus we obtain a contradiction
(as a product of two units cannot be zero).
\end{proof}

\paragraph{Second attempt.} Now, we try to bring in the formula for
the interpolation of determinants.

\begin{lemma}[using interpolation of determinants]
...
\end{lemma}

\begin{proof}
Let $A,B,C\subseteq S$ be disjoint. Then set $a\in \bigjoin{A}$
By induction hypothesis it holds that
\begin{align}
\sum_{A'\in\binom{A}{r+1}}{P(A'\setjoin B)\prod_{z\in A\setminus A'\setjoin C}\det(z,A'\setjoin B)^{-1}}=0
\end{align}
... this is BALLs lemma ... apply it for $C-> C\setminus\{c\}$ and sum
over $c$.
Multiply this by $\sgn(c,C\setminus\{c\})\det(C\setminus\{c\},B,a)$
and sum over $c\in C$ to get
\begin{align}
\sum_{c\in
  C}\sgn(c,C\setminus\{c\})\det(C\setminus\{c\},B,a)\sum_{A'\in\binom{A}{r+1}}{P(A'\setjoin
  B)\prod_{z\in(A\setminus A')\setjoin(C\setminus\{c\})}\det(z,A'\setjoin
  B)^{-1}}=0
\end{align}
The terms where $a\in A'$ sum to zero by the interpolation of
determinants. Thus we arrive at ... $C$ grows ... think about
\end{proof}

... Some great things will follow.

\section{A connection to the Kneser graphs $KG(2d-3,d-2)$}

In this section we want to give an alternative proof of the MDS main conjecture for $d\leq p$ using essentially the same means as before and some known facts about the eigenvalues of Kneser graphs.

We recall the interpolation lemma for the tangent polynomials which states that for disjoint subsets $A,B\subset S$ ($\abs{A}=t+2$, $\abs{B}=d-2$ and w.l.o.g. $t+d < \abs{S}$ using the dualisation argument)
we have that

\begin{equation}
\sum_{a\in A}{T_C(a)\prod_{z\in A\setminus \{a\}}\det(z,B,a)^{-1}}=0\label{eq:interpol}
\end{equation}

(this is Ball's \& de Beule's lemma for $r=1$). Now, we define the interpolation terms as

\begin{equation}
I(C,D):=T_{C\setminus\{c\}}(c)\prod_{d\in D}\det(d,C,c)^{-1}
\end{equation}

where $C,D\subset S$, $\abs{C}=d-1$, $\abs{D}=t+1$ and due to Segre's lemma (simplified version), i.e. the second claim in Ball's \& de Beule's lemma this is a definition.
If we now rewrite the equation (\ref{eq:interpol}) one sees that we get a linear system of $\binom{\abs{S}}{t+2,d-2,|S|-d-t}$ equations in $\binom{\abs{S}}{t+1,d-1,|S|-d-t}$ variables, namely

\begin{equation}
\sum_{a\in A}{I(A\setminus\{a\}, B\setjoin\{a\})}\label{eq:linsys}
\end{equation}
for $A\in\binom{S}{t+2}$ and $B\in\binom{S}{d-2}$. Moreover, this system decomposes into $\binom{\abs{S}}{d+t}$ independent components on which $A\setjoin B=E$ where $E\in\binom{S}{t+d}$ is constant.
Moreover, note that for the critical case $t=d-3$ there are the same number of variables as equations (namely $\binom{\abs{S}}{d-1,d-2,\abs{S}-2d+3}$).
We will now show that in this case, each such component can be interpreted as the adjacency matrix of the Kneser graph $KG(2d-3,d-2)$ and deduce that it is regular when interpreted as a matrix in $\ints_p$ where $p\leq d$ using a fact about the eigenvalues of Kneser graphs.

\begin{lemma}
Assume $t=d-3$ (i.e. $\abs{S}=q+2$).
Let $E\in\binom{S}{t+d}$. Then the component of the linear system (\ref{eq:linsys}) on which $A\setjoin B=E$ is the adjacency matrix of the graph $KG(2d-3,d-2)$.
\end{lemma} 

\begin{proof}
Let $M=(m_{(A,B),(C,D)})$ be the corresponding matrix of the whole system (\ref{eq:linsys}), where $A$, $B$ are as above and $C$, $D$ can be interpreted to $A\setminus\{a\}$ and $B\setjoin\{a\}$ in the above.
Then we have ($A,D\in\binom{S}{d-1}$, $B,C\in\binom{S}{d-2}$, $A\setmeet B=C\setmeet D = \emptyset$)
\begin{equation}
m_{(A,B),(C,D)}=
\begin{cases}
1 :& A\setjoin B = C\setjoin D \lgand A\supset C (\lgand B\subset D)\\
0 :& \text{otherwise}  
\end{cases}\text{.}
\end{equation}

From this it follows that the matrix $N:=(n_{(A,B),(D,C)}):=(m_{(A,B),(C,D)})$ is symmetric matrix in $\ints^{\mathcal{I}\times\mathcal{I}}$ where $\mathcal{I}:=\{(A,B)\in\binom{S}{d-1}\times\binom{S}{d-2}:A\setmeet B=\emptyset\}$. Thus $N$ is the adjacency matrix of an undirected graph $G=(V,E)$ on $\binom{\abs{S}}{d-1,d-2,\abs{S}-2d+3}$ vertices.
Now, when restricting ourselves to the component $C=(V_C,E_c)$ of $G$ where $A\setjoin B=E$. It is now an easy matter to check that $C\iso KG(2d-3,d-2)$ as for $(A_1,B_1),(A_2,B_2)\in E_C$
\begin{equation}
n_{(A_1,B_1),(A_2,B_2)}=
\begin{cases}
1 :& A_1\supset B_2 = C (\lgand A_2\supset B_1)\\
0 :& \text{otherwise}  
\end{cases}
=
\begin{cases}
1 :& B_1\setmeet B_2 = \emptyset\\
0 :& \text{otherwise}  
\end{cases}
\end{equation}
and of course on $C$ we only need to label a vertex by its second component $B$ as the first component $A$ can be recaptured by $A=E\setminus B$.
\end{proof}

For $d\leq p$ this can be easily lead to contradiction using a well-known fact about the eigenvalues of Kneser graphs.

\begin{lemma}[graph spectrum of Kneser graphs]
Let $2k\leq n$. Then the eigenvalues in $\ints$ of the adjacency matrix of the Kneser graph $KG(n,k)$ are
\begin{equation}
\lambda_j:=(-1)^j\binom{n-k-j}{k-j}
\end{equation}
for $j=0,\ldots,k$ where $\lambda_j$ has geometric and algebraic multiplicity $\binom{n}{j}-\binom{n}{j-1}$.
\end{lemma}

\begin{proof}
... to be done ...
\end{proof}

From this we get a direct proof of corollary \ref{cor:mdsconjpcase} as for $d\leq p$ there are no eigenvalues divisible by $p$ and thus the system of equations (\ref{eq:linsys}) must be a regular matrix in the case $t=d-3$. Thus it would follow that $I(C,D)=0$ for all $C,D\subset S$, $\abs{C}=d-1$, $\abs{D}=d-2$ which contradicts the fact that all these expressions must be units in $\field_q$ (by definition).
It is also possible to do the above argument without the knowledge of the previous lemma. To do this, note that $S_{2d-3}$ acts on the kernel of the adjacency matrix $M$ of $KG(2d-3,d-2)$ in $\field_q$. Assume that $d\leq p$ and that $M$ is singular. Then consider a nontrivial element of its kernel $c$. Summing the images of $c$ under all elements of $S_{2d-3}$ gives a vector which has $(d-1)!(d-2)!$ times the sum of all components of $c$ in each component. By the assumption, this cannot be the zero vector since $(d-1)!(d-2)!$ is a unit mod $p$. But then it follows that $d-1\equiv 0$ mod $p$ (plugging this vector in the equation of $M$) and thus $d>p$ which is a contradiction.   

\begin{remark}
Note that if $p\geq d-1\equiv 0$ mod $p$ then we obviously have the solution $I(C,D)=1$ for all $C,D$ to the system (\ref{eq:linsys}) but many other cases there should not be that a solution with only nonzero components does exist (which would extablish the MDS conjecture in these cases, but should be very difficult to prove).
\end{remark}
\end{document}

\message{ !name(OnTheRAIDProblem.tex) !offset(-869) }
